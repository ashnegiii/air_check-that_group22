{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfnQvGfvtH1w"
   },
   "source": [
    "# Getting started\n",
    "\n",
    "### CLEF 2025 - CheckThat! Lab  - Task 4 Scientific Web Discourse - Subtask 4b (Scientific Claim Source Retrieval)\n",
    "\n",
    "This notebook enables participants of subtask 4b to quickly get started. It includes the following:\n",
    "- Code to upload data, including:\n",
    "    - code to upload the collection set (CORD-19 academic papers' metadata)\n",
    "    - code to upload the query set (tweets with implicit references to CORD-19 papers)\n",
    "- Code to run a baseline retrieval model (BM25)\n",
    "- Code to evaluate the baseline model\n",
    "\n",
    "Participants are free to use this notebook and add their own models for the competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpDCfBMouNAL"
   },
   "source": [
    "# 1) Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\python312\\lib\\site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1742975967136,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "rQPqDKP_QHFM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8N7h9BhQI5m"
   },
   "source": [
    "## 1.a) Import the collection set\n",
    "The collection set contains metadata of CORD-19 academic papers.\n",
    "\n",
    "The preprocessed and filtered CORD-19 dataset is available on the Gitlab repository here: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b\n",
    "\n",
    "Participants should first download the file then upload it on the Google Colab session with the following steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1742975971100,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "2GQI4HcKR6hS"
   },
   "outputs": [],
   "source": [
    "# 1) Download the collection set from the Gitlab repository: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b\n",
    "# 2) Drag and drop the downloaded file to the \"Files\" section (left vertical menu on Colab)\n",
    "# 3) Modify the path to your local file path\n",
    "PATH_COLLECTION_DATA = 'subtask4b_collection_data.pkl' #MODIFY PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1742975975524,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "SYBB3UYbMwTA"
   },
   "outputs": [],
   "source": [
    "df_collection = pd.read_pickle(PATH_COLLECTION_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1742975976305,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "4v3lygNOQQSn",
    "outputId": "ee5b9abd-f889-4a4e-ce11-32d2691433cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7718 entries, 162 to 1056448\n",
      "Data columns (total 17 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   cord_uid          7718 non-null   object        \n",
      " 1   source_x          7718 non-null   object        \n",
      " 2   title             7718 non-null   object        \n",
      " 3   doi               7677 non-null   object        \n",
      " 4   pmcid             4959 non-null   object        \n",
      " 5   pubmed_id         6233 non-null   object        \n",
      " 6   license           7718 non-null   object        \n",
      " 7   abstract          7718 non-null   object        \n",
      " 8   publish_time      7715 non-null   object        \n",
      " 9   authors           7674 non-null   object        \n",
      " 10  journal           6668 non-null   object        \n",
      " 11  mag_id            0 non-null      float64       \n",
      " 12  who_covidence_id  528 non-null    object        \n",
      " 13  arxiv_id          20 non-null     object        \n",
      " 14  label             7718 non-null   object        \n",
      " 15  time              7715 non-null   datetime64[ns]\n",
      " 16  timet             7718 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(14)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_collection.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1742975978238,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "9veNFFGDZRx7",
    "outputId": "5eec7f85-7d20-44d7-8986-a85cb00533d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>mag_id</th>\n",
       "      <th>who_covidence_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "      <th>timet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Professional and Home-Made Face Masks Reduce E...</td>\n",
       "      <td>10.1371/journal.pone.0002618</td>\n",
       "      <td>PMC2440799</td>\n",
       "      <td>18612429</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>BACKGROUND: Governments are preparing for a po...</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>van der Sande, Marianne; Teunis, Peter; Sabel,...</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>1215561600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>PMC</td>\n",
       "      <td>The Failure of R (0)</td>\n",
       "      <td>10.1155/2011/527610</td>\n",
       "      <td>PMC3157160</td>\n",
       "      <td>21860658</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>The basic reproductive ratio, R (0), is one of...</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>Li, Jing; Blakeley, Daniel; Smith?, Robert J.</td>\n",
       "      <td>Comput Math Methods Med</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>1313452800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Pulmonary sequelae in a patient recovered from...</td>\n",
       "      <td>10.4103/0970-2113.99118</td>\n",
       "      <td>PMC3424870</td>\n",
       "      <td>22919170</td>\n",
       "      <td>cc-by-nc-sa</td>\n",
       "      <td>The pandemic of swine flu (H1N1) influenza spr...</td>\n",
       "      <td>2012</td>\n",
       "      <td>Singh, Virendra; Sharma, Bharat Bhushan; Patel...</td>\n",
       "      <td>Lung India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1325376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>ycxyn2a2</td>\n",
       "      <td>PMC</td>\n",
       "      <td>What was the primary mode of smallpox transmis...</td>\n",
       "      <td>10.3389/fcimb.2012.00150</td>\n",
       "      <td>PMC3509329</td>\n",
       "      <td>23226686</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>The mode of infection transmission has profoun...</td>\n",
       "      <td>2012-11-29</td>\n",
       "      <td>Milton, Donald K.</td>\n",
       "      <td>Front Cell Infect Microbiol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ycxyn2a2</td>\n",
       "      <td>2012-11-29</td>\n",
       "      <td>1354147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>zxe95qy9</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Lessons from the History of Quarantine, from P...</td>\n",
       "      <td>10.3201/eid1902.120312</td>\n",
       "      <td>PMC3559034</td>\n",
       "      <td>23343512</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>In the new millennium, the centuries-old strat...</td>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>Tognotti, Eugenia</td>\n",
       "      <td>Emerg Infect Dis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zxe95qy9</td>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>1359849600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cord_uid source_x                                              title  \\\n",
       "162   umvrwgaw      PMC  Professional and Home-Made Face Masks Reduce E...   \n",
       "611   spiud6ok      PMC                               The Failure of R (0)   \n",
       "918   aclzp3iy      PMC  Pulmonary sequelae in a patient recovered from...   \n",
       "993   ycxyn2a2      PMC  What was the primary mode of smallpox transmis...   \n",
       "1053  zxe95qy9      PMC  Lessons from the History of Quarantine, from P...   \n",
       "\n",
       "                               doi       pmcid pubmed_id      license  \\\n",
       "162   10.1371/journal.pone.0002618  PMC2440799  18612429        cc-by   \n",
       "611            10.1155/2011/527610  PMC3157160  21860658        cc-by   \n",
       "918        10.4103/0970-2113.99118  PMC3424870  22919170  cc-by-nc-sa   \n",
       "993       10.3389/fcimb.2012.00150  PMC3509329  23226686        cc-by   \n",
       "1053        10.3201/eid1902.120312  PMC3559034  23343512        no-cc   \n",
       "\n",
       "                                               abstract publish_time  \\\n",
       "162   BACKGROUND: Governments are preparing for a po...   2008-07-09   \n",
       "611   The basic reproductive ratio, R (0), is one of...   2011-08-16   \n",
       "918   The pandemic of swine flu (H1N1) influenza spr...         2012   \n",
       "993   The mode of infection transmission has profoun...   2012-11-29   \n",
       "1053  In the new millennium, the centuries-old strat...   2013-02-03   \n",
       "\n",
       "                                                authors  \\\n",
       "162   van der Sande, Marianne; Teunis, Peter; Sabel,...   \n",
       "611       Li, Jing; Blakeley, Daniel; Smith?, Robert J.   \n",
       "918   Singh, Virendra; Sharma, Bharat Bhushan; Patel...   \n",
       "993                                   Milton, Donald K.   \n",
       "1053                                  Tognotti, Eugenia   \n",
       "\n",
       "                          journal  mag_id who_covidence_id arxiv_id     label  \\\n",
       "162                      PLoS One     NaN              NaN      NaN  umvrwgaw   \n",
       "611       Comput Math Methods Med     NaN              NaN      NaN  spiud6ok   \n",
       "918                    Lung India     NaN              NaN      NaN  aclzp3iy   \n",
       "993   Front Cell Infect Microbiol     NaN              NaN      NaN  ycxyn2a2   \n",
       "1053             Emerg Infect Dis     NaN              NaN      NaN  zxe95qy9   \n",
       "\n",
       "           time       timet  \n",
       "162  2008-07-09  1215561600  \n",
       "611  2011-08-16  1313452800  \n",
       "918  2012-01-01  1325376000  \n",
       "993  2012-11-29  1354147200  \n",
       "1053 2013-02-03  1359849600  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collection.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAUiDU0xXLBt"
   },
   "source": [
    "## 1.b) Import the query set\n",
    "\n",
    "The query set contains tweets with implicit references to academic papers from the collection set.\n",
    "\n",
    "The preprocessed query set is available on the Gitlab repository here: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b\n",
    "\n",
    "Participants should first download the file then upload it on the Google Colab session with the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1742975982410,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "v8gwkZDSXPsd"
   },
   "outputs": [],
   "source": [
    "# 1) Download the query tweets from the Gitlab repository: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b?ref_type=heads\n",
    "# 2) Drag and drop the downloaded file to the \"Files\" section (left vertical menu on Colab)\n",
    "# 3) Modify the path to your local file path\n",
    "PATH_QUERY_TRAIN_DATA = 'subtask4b_query_tweets_train.tsv' #MODIFY PATH\n",
    "PATH_QUERY_DEV_DATA = 'subtask4b_query_tweets_dev.tsv' #MODIFY PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1742976006985,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "VqxjYq2tYDmE"
   },
   "outputs": [],
   "source": [
    "df_query_train = pd.read_csv(PATH_QUERY_TRAIN_DATA, sep = '\\t')\n",
    "df_query_dev = pd.read_csv(PATH_QUERY_DEV_DATA, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1742976030778,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "B5X8FwLhLY3u",
    "outputId": "36e21737-8257-4568-8346-0d3e0980ee53"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>3qvh482o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>r58aohnu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>I recall early on reading that researchers who...</td>\n",
       "      <td>sts48u9i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>You know you're credible when NIH website has ...</td>\n",
       "      <td>3sr2exq9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>Resistance to antifungal medications is a grow...</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid\n",
       "0       16  covid recovery: this study from the usa reveal...  3qvh482o\n",
       "1       69  \"Among 139 clients exposed to two symptomatic ...  r58aohnu\n",
       "2       73  I recall early on reading that researchers who...  sts48u9i\n",
       "3       93  You know you're credible when NIH website has ...  3sr2exq9\n",
       "4       96  Resistance to antifungal medications is a grow...  ybwwmyqy"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1742976032804,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "t6gDlBZnLcdH",
    "outputId": "11cd57d2-a4b7-4b06-a9af-9ba5e29c191b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1400 entries, 0 to 1399\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   post_id     1400 non-null   int64 \n",
      " 1   tweet_text  1400 non-null   object\n",
      " 2   cord_uid    1400 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 32.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_query_dev.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jr_BDzufPmmP"
   },
   "source": [
    "# 2) Running the baseline\n",
    "The following code runs a BM25 baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3156,
     "status": "ok",
     "timestamp": 1742976045832,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "BHfJ7ItxO8u8",
    "outputId": "8a4d8f08-31c0-4a9d-814e-b921b80fbe35"
   },
   "outputs": [],
   "source": [
    "# !pip install rank_bm25\n",
    "from rank_bm25 import BM25Okapi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1414,
     "status": "ok",
     "timestamp": 1742976047296,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "jXCC7K_ZPQL2"
   },
   "outputs": [],
   "source": [
    "# Create the BM25 corpus\n",
    "corpus = df_collection[:][['title', 'abstract']].apply(lambda x: f\"{x['title']} {x['abstract']}\", axis=1).tolist()\n",
    "cord_uids = df_collection[:]['cord_uid'].tolist()\n",
    "tokenized_corpus = [doc.split(' ') for doc in corpus]\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742976047304,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "e8NeJWGYPQZG"
   },
   "outputs": [],
   "source": [
    "def get_top_cord_uids(query):\n",
    "  text2bm25top = {}\n",
    "  if query in text2bm25top.keys():\n",
    "      return text2bm25top[query]\n",
    "  else:\n",
    "      tokenized_query = query.split(' ')\n",
    "      doc_scores = bm25.get_scores(tokenized_query)\n",
    "      indices = np.argsort(-doc_scores)[:5]\n",
    "      bm25_topk = [cord_uids[x] for x in indices]\n",
    "\n",
    "      text2bm25top[query] = bm25_topk\n",
    "      return bm25_topk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Fk4-BqEtTgUj"
   },
   "outputs": [],
   "source": [
    "# Retrieve topk candidates using the BM25 model\n",
    "df_query_train['bm25_topk'] = df_query_train['tweet_text'].apply(lambda x: get_top_cord_uids(x))\n",
    "df_query_dev['bm25_topk'] = df_query_dev['tweet_text'].apply(lambda x: get_top_cord_uids(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVKBlTCZUMSc"
   },
   "source": [
    "# 3) Evaluating the baseline\n",
    "The following code evaluates the BM25 retrieval baseline on the query set using the Mean Reciprocal Rank score (MRR@5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742976555898,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "c-vdGWXXTgjZ"
   },
   "outputs": [],
   "source": [
    "# Evaluate retrieved candidates using MRR@k\n",
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        #performances.append(data[\"in_topx\"].mean())\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "    return d_performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1742976568622,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "xLX9SMg5USkH",
    "outputId": "7c414679-6486-4e08-dffe-23d8cffbddf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on the train set: {1: np.float64(0.5081303975725512), 5: np.float64(0.5509777224513084), 10: np.float64(0.5509777224513084)}\n",
      "Results on the dev set: {1: np.float64(0.5057142857142857), 5: np.float64(0.5522738095238094), 10: np.float64(0.5522738095238094)}\n"
     ]
    }
   ],
   "source": [
    "results_train = get_performance_mrr(df_query_train, 'cord_uid', 'bm25_topk')\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', 'bm25_topk')\n",
    "# Printed MRR@k results in the following format: {k: MRR@k}\n",
    "print(f\"Results on the train set: {results_train}\")\n",
    "print(f\"Results on the dev set: {results_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RazcRTV84KQC"
   },
   "source": [
    "# 4) Exporting results to prepare the submission on Codalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1742976603546,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "DFng4ocDw3Hk"
   },
   "outputs": [],
   "source": [
    "df_query_dev['preds'] = df_query_dev['bm25_topk'].apply(lambda x: x[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1742976608184,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "nAVBQYh_xP8O"
   },
   "outputs": [],
   "source": [
    "df_query_dev[['post_id', 'preds']].to_csv('predictions.tsv', index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opGI1H1h4Og5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Neural Re-ranking Model\n",
    "This section implements a neural re-ranking model that improves upon the BM25 baseline by using BERT and cross-attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/44/80/b353c024e6b624cd9ce1d66dcb9d24e0294680f95b369f19280e241a0159/torch-2.7.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading torch-2.7.0-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/36/f8/1f086942bc6a044e4e68dacf6de761a45367795efd5f57ad356765691c79/transformers-4.52.3-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
      "     ---------------------------------------- 0.0/40.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 40.2/40.2 kB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\python312\\lib\\site-packages (4.67.0)\n",
      "Requirement already satisfied: rank_bm25 in c:\\python312\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ash\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Obtaining dependency information for sympy>=1.13.3 from https://files.pythonhosted.org/packages/a2/09/77d55d46fd61b4a135c444fc97158ef34a095e5681d0a6c10b75bf356191/sympy-1.14.0-py3-none-any.whl.metadata\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/eb/8d/776adee7bbf76365fdd7f2552710282c79a4ead5d2a46408c9043a2b70ba/networkx-3.5-py3-none-any.whl.metadata\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ash\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.4)\n",
      "Collecting fsspec (from torch)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/bb/61/78c7b3851add1481b048b5fdc29067397a1784e2910592bc81bb3f608635/fsspec-2025.5.1-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Obtaining dependency information for setuptools from https://files.pythonhosted.org/packages/a3/dc/17031897dae0efacfea57dfd3a82fdd2a2aeb58e0ff71b77b87e44edc772/setuptools-80.9.0-py3-none-any.whl.metadata\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.30.0 from https://files.pythonhosted.org/packages/32/30/532fe57467a6cc7ff2e39f088db1cb6d6bf522f724a4a5c7beda1282d5a6/huggingface_hub-0.32.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.32.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python312\\lib\\site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/38/ec/ad2d7de49a600cdb8dd78434a1aeffe28b9d6fc42eb36afab4a27ad23384/regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.5/41.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\ash\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Obtaining dependency information for tokenizers<0.22,>=0.21 from https://files.pythonhosted.org/packages/e6/b6/072a8e053ae600dcc2ac0da81a23548e3b523301a442a6ca900e92ac35be/tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Obtaining dependency information for safetensors>=0.4.3 from https://files.pythonhosted.org/packages/69/e2/b011c38e5394c4c18fb5500778a55ec43ad6106126e74723ffaee246f56e/safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\ash\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Obtaining dependency information for mpmath<1.4,>=1.1.0 from https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ash\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading torch-2.7.0-cp312-cp312-win_amd64.whl (212.5 MB)\n",
      "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/212.5 MB 3.5 MB/s eta 0:01:01\n",
      "   ---------------------------------------- 0.5/212.5 MB 6.4 MB/s eta 0:00:33\n",
      "   ---------------------------------------- 1.5/212.5 MB 10.9 MB/s eta 0:00:20\n",
      "    --------------------------------------- 2.9/212.5 MB 16.6 MB/s eta 0:00:13\n",
      "    --------------------------------------- 4.4/212.5 MB 18.8 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 5.7/212.5 MB 20.3 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 7.0/212.5 MB 22.5 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 9.1/212.5 MB 25.3 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 10.8/212.5 MB 32.8 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 12.7/212.5 MB 36.4 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 14.1/212.5 MB 36.4 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 16.0/212.5 MB 38.5 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 18.3/212.5 MB 43.7 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 20.5/212.5 MB 43.5 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 23.0/212.5 MB 46.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 25.4/212.5 MB 50.1 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 28.0/212.5 MB 54.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 30.0/212.5 MB 54.7 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 32.9/212.5 MB 54.7 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 35.3/212.5 MB 54.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 37.9/212.5 MB 54.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 38.0/212.5 MB 43.5 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 38.3/212.5 MB 38.5 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 38.7/212.5 MB 34.4 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 41.3/212.5 MB 34.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 44.9/212.5 MB 34.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 48.9/212.5 MB 73.1 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 52.2/212.5 MB 81.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 54.3/212.5 MB 65.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 57.7/212.5 MB 65.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 60.6/212.5 MB 65.2 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 64.2/212.5 MB 72.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 64.2/212.5 MB 65.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 64.2/212.5 MB 65.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 67.3/212.5 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 70.2/212.5 MB 43.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 71.5/212.5 MB 38.5 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 73.6/212.5 MB 34.4 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 74.9/212.5 MB 46.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 77.8/212.5 MB 43.5 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 80.0/212.5 MB 40.9 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 82.8/212.5 MB 50.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 85.7/212.5 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 88.1/212.5 MB 59.8 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 88.4/212.5 MB 43.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 88.5/212.5 MB 38.5 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 89.3/212.5 MB 32.7 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 92.3/212.5 MB 34.4 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 92.5/212.5 MB 31.2 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 93.1/212.5 MB 27.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 94.4/212.5 MB 26.2 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 97.3/212.5 MB 25.2 MB/s eta 0:00:05\n",
      "   ------------------ -------------------- 100.4/212.5 MB 40.9 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 103.1/212.5 MB 50.4 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 105.2/212.5 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------- ------------------- 105.8/212.5 MB 50.4 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 106.1/212.5 MB 40.9 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 108.1/212.5 MB 38.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 110.7/212.5 MB 36.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 111.3/212.5 MB 32.8 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 111.4/212.5 MB 29.8 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 111.6/212.5 MB 26.2 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 112.1/212.5 MB 23.4 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 115.0/212.5 MB 24.2 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 118.8/212.5 MB 31.2 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 120.0/212.5 MB 29.7 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 120.2/212.5 MB 27.3 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 120.4/212.5 MB 23.4 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 121.3/212.5 MB 23.4 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 124.9/212.5 MB 36.4 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 124.9/212.5 MB 36.4 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 127.9/212.5 MB 31.2 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 129.1/212.5 MB 27.3 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 129.4/212.5 MB 25.1 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 129.7/212.5 MB 22.5 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 130.3/212.5 MB 22.6 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 134.8/212.5 MB 31.2 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 136.3/212.5 MB 32.8 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 137.3/212.5 MB 28.5 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 139.6/212.5 MB 34.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 141.8/212.5 MB 46.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 142.2/212.5 MB 40.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 142.8/212.5 MB 34.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 145.1/212.5 MB 32.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 145.9/212.5 MB 29.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 147.1/212.5 MB 29.7 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 150.2/212.5 MB 32.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 152.8/212.5 MB 40.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 155.7/212.5 MB 46.7 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 159.2/212.5 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 161.9/212.5 MB 65.2 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 165.5/212.5 MB 73.1 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 168.7/212.5 MB 73.1 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 171.8/212.5 MB 65.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 175.9/212.5 MB 72.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 178.7/212.5 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 182.7/212.5 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 186.4/212.5 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 189.4/212.5 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 190.1/212.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 190.6/212.5 MB 46.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 191.6/212.5 MB 38.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 193.7/212.5 MB 38.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 195.0/212.5 MB 38.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 195.0/212.5 MB 38.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 195.1/212.5 MB 27.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 195.5/212.5 MB 23.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 195.9/212.5 MB 22.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 196.1/212.5 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 197.5/212.5 MB 18.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 200.1/212.5 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 201.5/212.5 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 205.3/212.5 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  207.2/212.5 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  210.0/212.5 MB 46.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.5/212.5 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 212.5/212.5 MB 22.6 MB/s eta 0:00:00\n",
      "Downloading transformers-4.52.3-py3-none-any.whl (10.5 MB)\n",
      "   ---------------------------------------- 0.0/10.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.5 MB 9.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.9/10.5 MB 30.4 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.8/10.5 MB 40.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.6/10.5 MB 44.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.4/10.5 MB 43.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.5/10.5 MB 40.9 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.32.2-py3-none-any.whl (509 kB)\n",
      "   ---------------------------------------- 0.0/510.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 510.0/510.0 kB ? eta 0:00:00\n",
      "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "   ---------------------------------------- 0.0/199.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 199.1/199.1 kB 11.8 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "   ---------------------------------------- 0.0/273.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 273.6/273.6 kB 16.5 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "   ---------------------------------------- 0.0/308.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 308.9/308.9 kB 19.9 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/6.3 MB 68.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.0/6.3 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.9/6.3 MB 38.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 40.3 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 1.1/2.4 MB 34.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 38.5 MB/s eta 0:00:00\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 126.5 MB/s eta 0:00:00\n",
      "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 79.4 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 35.1 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, setuptools, safetensors, regex, networkx, fsspec, torch, huggingface-hub, tokenizers, transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Python312\\\\share'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required dependencies\n",
    "!pip install torch transformers tqdm rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\python312\\lib\\site-packages (2.1.2)\n",
      "Collecting numpy\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/36/fa/8c9210162ca1b88529ab76b41ba02d433fd54fecaf6feb70ef9f124683f1/numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ------------------- ------------------ 30.7/60.8 kB 640.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.8/60.8 kB 803.2 kB/s eta 0:00:00\n",
      "Downloading numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/12.6 MB 2.0 MB/s eta 0:00:07\n",
      "    --------------------------------------- 0.2/12.6 MB 3.3 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.3/12.6 MB 2.7 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.5/12.6 MB 3.0 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.7/12.6 MB 3.6 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.9/12.6 MB 3.3 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.1/12.6 MB 3.5 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.4/12.6 MB 3.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.5/12.6 MB 3.9 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 3.8 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.9/12.6 MB 4.0 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.2/12.6 MB 4.0 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.5/12.6 MB 4.2 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.8/12.6 MB 4.4 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.1/12.6 MB 4.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 4.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.7/12.6 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.1/12.6 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.5/12.6 MB 5.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.8/12.6 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.3/12.6 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.7/12.6 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.2/12.6 MB 5.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.7/12.6 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.2/12.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.8/12.6 MB 6.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.3/12.6 MB 6.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.6/12.6 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.1/12.6 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.8/12.6 MB 7.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.4/12.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.2/12.6 MB 8.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.7/12.6 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 10.2 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "  Rolling back uninstall of numpy\n",
      "  Moving to c:\\python312\\lib\\site-packages\\numpy-2.1.2-cp312-cp312-win_amd64.whl\n",
      "   from C:\\Users\\Ash\\AppData\\Local\\Temp\\pip-uninstall-9ugno_bn\\numpy-2.1.2-cp312-cp312-win_amd64.whl\n",
      "  Moving to c:\\python312\\lib\\site-packages\\numpy-2.1.2.dist-info\\\n",
      "   from C:\\Python312\\Lib\\site-packages\\~umpy-2.1.2.dist-info\n",
      "  Moving to c:\\python312\\lib\\site-packages\\numpy.libs\\\n",
      "   from C:\\Python312\\Lib\\site-packages\\~umpy.libs\n",
      "  Moving to c:\\python312\\lib\\site-packages\\numpy\\\n",
      "   from C:\\Python312\\Lib\\site-packages\\~umpy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python312\\\\Scripts\\\\f2py.exe' -> 'C:\\\\Python312\\\\Scripts\\\\f2py.exe.deleteme'\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;66;03m# Import neural re-ranking model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneural_reranker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeuralReranker, Reranker, prepare_training_data, train_reranker\n",
      "File \u001b[1;32mc:\\Users\\Ash\\OneDrive\\Master\\3. Semester\\AIR\\workspace\\clef2025-checkthat-lab\\task4\\subtask_4b\\neural_reranker.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertModel, BertTokenizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os# Import neural re-ranking model\n",
    "from neural_reranker import NeuralReranker, Reranker, prepare_training_data, train_reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prepare_training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Prepare training data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreparing training data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m training_data \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_training_data\u001b[49m(df_query_train, df_collection)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prepare_training_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Prepare training data\n",
    "print(\"Preparing training data...\")\n",
    "training_data = prepare_training_data(df_query_train, df_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = NeuralReranker(bert_model_name='bert-base-uncased')\n",
    "\n",
    "# Train with smaller batch size and gradient accumulation\n",
    "print(\"Training neural reranker...\")\n",
    "trained_model = train_reranker(\n",
    "    model=model,\n",
    "    training_data=training_data,\n",
    "    num_epochs=3,\n",
    "    batch_size=2,  # Smaller batch size\n",
    "    learning_rate=2e-5,\n",
    "    gradient_accumulation_steps=1  # Added gradient accumulation\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "print(\"Saving model...\")\n",
    "torch.save(trained_model.state_dict(), 'neural_reranker_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Neural Re-ranking Model Evaluation\n",
    "This section implements the evaluation pipeline for the neural re-ranking model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_mrr(data, col_gold, col_pred, list_k=[1, 5, 10]):\n",
    "    \"\"\"Calculate MRR@k for evaluation\"\"\"\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(\n",
    "            lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) \n",
    "                      if x[col_gold] in [i for i in x[col_pred][:k]] else 0), \n",
    "            axis=1\n",
    "        )\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "    return d_performance\n",
    "\n",
    "def evaluate_reranker(model, df_dev, df_collection, bm25_model, top_k=5):\n",
    "    \"\"\"Evaluate the reranker on the development set\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for _, row in tqdm(df_dev.iterrows(), desc=\"Evaluating\"):\n",
    "        query = row['tweet_text']\n",
    "        gold_doc_id = row['cord_uid']\n",
    "        \n",
    "        # Get BM25 candidates\n",
    "        tokenized_query = query.split(' ')\n",
    "        doc_scores = bm25_model.get_scores(tokenized_query)\n",
    "        bm25_indices = np.argsort(-doc_scores)[:top_k]\n",
    "        bm25_candidates = [df_collection.iloc[i]['cord_uid'] for i in bm25_indices]\n",
    "        \n",
    "        # Get document texts for reranking\n",
    "        candidate_texts = []\n",
    "        for doc_id in bm25_candidates:\n",
    "            doc = df_collection[df_collection['cord_uid'] == doc_id].iloc[0]\n",
    "            candidate_texts.append(f\"{doc['title']} {doc['abstract']}\")\n",
    "        \n",
    "        # Get BM25 scores for candidates\n",
    "        bm25_scores = [doc_scores[i] for i in bm25_indices]\n",
    "        \n",
    "        # Rerank using neural model\n",
    "        reranker = Reranker(model=model)\n",
    "        reranked_docs = reranker.rerank(query, candidate_texts, bm25_scores)\n",
    "        \n",
    "        # Get reranked document IDs\n",
    "        reranked_ids = [bm25_candidates[i] for i, _ in reranked_docs]\n",
    "        \n",
    "        results.append({\n",
    "            'post_id': row['post_id'],\n",
    "            'gold_doc_id': gold_doc_id,\n",
    "            'predicted_docs': reranked_ids\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1) Train and Evaluate the Neural Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "print(\"Preparing training data...\")\n",
    "training_data = prepare_training_data(df_query_train, df_collection)\n",
    "\n",
    "# Initialize and train model\n",
    "print(\"Training neural reranker...\")\n",
    "model = NeuralReranker()\n",
    "model = train_reranker(\n",
    "    model=model,\n",
    "    training_data=training_data,\n",
    "    num_epochs=3,\n",
    "    batch_size=8,\n",
    "    learning_rate=2e-5\n",
    ")\n",
    "\n",
    "# Save trained model\n",
    "print(\"Saving model...\")\n",
    "torch.save(model.state_dict(), 'neural_reranker_model.pt')\n",
    "\n",
    "# Evaluate on dev set\n",
    "print(\"Evaluating on development set...\")\n",
    "results_df = evaluate_reranker(model, df_query_dev, df_collection, bm25)\n",
    "\n",
    "# Calculate MRR scores\n",
    "print(\"Calculating MRR scores...\")\n",
    "mrr_scores = get_performance_mrr(\n",
    "    results_df,\n",
    "    'gold_doc_id',\n",
    "    'predicted_docs',\n",
    "    list_k=[1, 5, 10]\n",
    ")\n",
    "\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(f\"MRR@1: {mrr_scores[1]:.4f}\")\n",
    "print(f\"MRR@5: {mrr_scores[5]:.4f}\")\n",
    "print(f\"MRR@10: {mrr_scores[10]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2) Test the Neural Reranker on Individual Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_query(query: str, model_path: str, df_collection: pd.DataFrame, top_k: int = 5):\n",
    "    \"\"\"Test the reranker on a single query\"\"\"\n",
    "    # Initialize BM25\n",
    "    corpus = df_collection[['title', 'abstract']].apply(\n",
    "        lambda x: f\"{x['title']} {x['abstract']}\", axis=1\n",
    "    ).tolist()\n",
    "    tokenized_corpus = [doc.split(' ') for doc in corpus]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    \n",
    "    # Get BM25 candidates\n",
    "    tokenized_query = query.split(' ')\n",
    "    doc_scores = bm25.get_scores(tokenized_query)\n",
    "    bm25_indices = np.argsort(-doc_scores)[:top_k]\n",
    "    bm25_candidates = [df_collection.iloc[i]['cord_uid'] for i in bm25_indices]\n",
    "    \n",
    "    # Get document texts for reranking\n",
    "    candidate_texts = []\n",
    "    for doc_id in bm25_candidates:\n",
    "        doc = df_collection[df_collection['cord_uid'] == doc_id].iloc[0]\n",
    "        candidate_texts.append(f\"{doc['title']} {doc['abstract']}\")\n",
    "    \n",
    "    # Get BM25 scores for candidates\n",
    "    bm25_scores = [doc_scores[i] for i in bm25_indices]\n",
    "    \n",
    "    # Load and initialize reranker\n",
    "    model = NeuralReranker()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    reranker = Reranker(model=model)\n",
    "    \n",
    "    # Rerank documents\n",
    "    reranked_docs = reranker.rerank(query, candidate_texts, bm25_scores)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nQuery: {query}\\n\")\n",
    "    print(\"BM25 Results:\")\n",
    "    for i, (doc_id, score) in enumerate(zip(bm25_candidates, bm25_scores)):\n",
    "        print(f\"{i+1}. Doc ID: {doc_id}, Score: {score:.4f}\")\n",
    "    \n",
    "    print(\"\\nNeural Reranker Results:\")\n",
    "    for i, (doc_id, score) in enumerate(zip(bm25_candidates, [score for _, score in reranked_docs])):\n",
    "        print(f\"{i+1}. Doc ID: {doc_id}, Score: {score:.4f}\")\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"New study shows that COVID-19 can be transmitted through airborne particles\",\n",
    "    \"Research indicates that wearing masks reduces the spread of respiratory diseases\",\n",
    "    \"Scientists discover potential treatment for severe COVID-19 cases\"\n",
    "]\n",
    "\n",
    "# Test each query\n",
    "for query in test_queries:\n",
    "    test_single_query(\n",
    "        query=query,\n",
    "        model_path='neural_reranker_model.pt',\n",
    "        df_collection=df_collection\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3) Save Predictions for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions for submission\n",
    "print(\"Saving predictions...\")\n",
    "results_df[['post_id', 'predicted_docs']].to_csv(\n",
    "    'neural_reranker_predictions.tsv',\n",
    "    index=None,\n",
    "    sep='\\t'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
